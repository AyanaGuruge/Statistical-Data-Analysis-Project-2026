{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72a05e7",
   "metadata": {},
   "source": [
    "# TKO_7093 - Statistical Data Analysis Project\n",
    "## Group 160\n",
    "\n",
    "## Team Members\n",
    "\n",
    "| Name                      | Student ID|\n",
    "| :--------                 | :-------: |\n",
    "| Ayana Kotuwegoda Guruge   | 2406865   |\n",
    "| Sheheryar Wahidi          | 2413773   |\n",
    "| Yagya Yadav               | 2409273   |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f39bb0",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74af0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed libraries\n",
    "#from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238d0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive')\n",
    "#!ls /content/drive/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da176379",
   "metadata": {},
   "source": [
    "### Following steps are carried out for the data preparation:\n",
    "\n",
    "This step is for checking the dataset, cleaning and structuring for further analysis (qualititative). \n",
    "\n",
    "* Data loaded from habits.data into a DataFrame matching the variables.\n",
    "* Missing values are checked and not removed.\n",
    "* Codes are converted into readable lables.\n",
    "* Checking all demographic values for sensible values.\n",
    "* Checking the validity of the ranges.\n",
    "* Replacing the invalid values of the variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8bdf068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 745 entries, 0 to 744\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   kohde   745 non-null    int64  \n",
      " 1   jasen   745 non-null    int64  \n",
      " 2   pvknro  745 non-null    int64  \n",
      " 3   sp      745 non-null    int64  \n",
      " 4   ASALUE  745 non-null    float64\n",
      " 5   IKAL1   745 non-null    int64  \n",
      " 6   A1      741 non-null    object \n",
      " 7   A2      737 non-null    object \n",
      " 8   A3      733 non-null    object \n",
      " 9   A4      736 non-null    object \n",
      " 10  A5      703 non-null    float64\n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 64.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kohde</th>\n",
       "      <th>jasen</th>\n",
       "      <th>pvknro</th>\n",
       "      <th>sp</th>\n",
       "      <th>ASALUE</th>\n",
       "      <th>IKAL1</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>380</td>\n",
       "      <td>450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>470</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62</td>\n",
       "      <td>640</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kohde  jasen  pvknro  sp  ASALUE  IKAL1   A1   A2  A3   A4   A5\n",
       "0  50002      1       1   1     1.0     49    0  560   0   80  1.0\n",
       "1  50002      1       2   1     1.0     49  380  450  10    0  1.0\n",
       "2  50003      1       1   2     2.0     41    0  470  30  100  1.0\n",
       "3  50003      1       2   2     2.0     41    0  550   0    0  1.0\n",
       "4  50004      2       1   1     1.0     62  640  410   0    0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset from Path\n",
    "data_path = \"habits.data\"\n",
    "columns = ['kohde', 'jasen', 'pvknro', 'sp', 'ASALUE', 'IKAL1', 'A1', 'A2', 'A3', 'A4', 'A5']\n",
    "df = pd.read_csv(data_path, sep=\";\", header=0, usecols=columns, na_values=['?'])\n",
    "\n",
    "# Initial exploration of the dataset    \n",
    "df.head()\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563607d",
   "metadata": {},
   "source": [
    "* Structure was checked because according to the instructions given as there are multiple rows of the same person.\n",
    "* This is more to show that one person can be recorded for more than one day. Changes will be done in task 1\n",
    "    * 6 columns (Household ID, Person ID, day type, sex, living area, age group) are demographic variables.\n",
    "    * 5 columns (A1-A5) which are activity variables.\n",
    "* A1 to A4 variables are shown as objects where it should be in numerics since it is the time spent in activities in minutes according to the text file. This is due to mixed formatting or missing values or both.\n",
    "* The appearance of A5 variable (Visiting library) in float which aslo should be in numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a485f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "kohde      0\n",
      "jasen      0\n",
      "pvknro     0\n",
      "sp         0\n",
      "ASALUE     0\n",
      "IKAL1      0\n",
      "A1         4\n",
      "A2         8\n",
      "A3        12\n",
      "A4         9\n",
      "A5        42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601b758",
   "metadata": {},
   "source": [
    "* It shows that there some missing values in the activity variables but no missing values in the demographic variables.\n",
    "\n",
    "* Number of missing values of activity columns:\n",
    "    * A1 - 4\n",
    "    * A2 - 8\n",
    "    * A3 - 12\n",
    "    * A4 - 9\n",
    "    * A5 - 42 \n",
    "\n",
    "* Missing values are kept as NaN.\n",
    "* Missing values are not always \"0 minutes spent\"/\" no activity\". It can also mean that the data entry was missed to be recorded or an error. Therefore, it is better to keep them as NaN value guessing or maintaining as 0 assuming that there was no activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a9e24",
   "metadata": {},
   "source": [
    "### Data Type Conversion and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07869c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      "kohde       int64\n",
      "jasen       int64\n",
      "pvknro      int64\n",
      "sp          int64\n",
      "ASALUE    float64\n",
      "IKAL1       int64\n",
      "A1        float64\n",
      "A2        float64\n",
      "A3        float64\n",
      "A4        float64\n",
      "A5        float64\n",
      "dtype: object\n",
      "\n",
      "Missing values per column\n",
      "kohde      0\n",
      "jasen      0\n",
      "pvknro     0\n",
      "sp         0\n",
      "ASALUE     0\n",
      "IKAL1      0\n",
      "A1        85\n",
      "A2        88\n",
      "A3        94\n",
      "A4        91\n",
      "A5        42\n",
      "dtype: int64\n",
      "\n",
      "DataFrame shape: (745, 11)\n"
     ]
    }
   ],
   "source": [
    "# Replace '?' with NaN for consistent value handling\n",
    "df_clean = df.replace('?', np.nan)\n",
    "\n",
    "# Convert demographic variables to appropriate types respectrively (all numeric in this case)\n",
    "df_clean['kohde'] = pd.to_numeric(df_clean['kohde'], errors='coerce')\n",
    "df_clean['jasen'] = pd.to_numeric(df_clean['jasen'], errors='coerce')\n",
    "df_clean['pvknro'] = pd.to_numeric(df_clean['pvknro'], errors='coerce')\n",
    "df_clean['sp'] = pd.to_numeric(df_clean['sp'], errors='coerce')\n",
    "df_clean['IKAL1'] = pd.to_numeric(df_clean['IKAL1'], errors='coerce')\n",
    "df_clean['ASALUE'] = pd.to_numeric(df_clean['ASALUE'], errors='coerce')\n",
    "\n",
    "# Activity variables converting to numeric, handling time format data\n",
    "for col in ['A1', 'A2', 'A3', 'A4', 'A5']:\n",
    "    # A1-A4 are minutes and A5 in yes/no format, convert accordingly\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "print(\"Data types after conversion:\")\n",
    "print(df_clean.dtypes)\n",
    "print(\"\\nMissing values per column\")\n",
    "print(df_clean.isnull().sum())\n",
    "print(\"\\nDataFrame shape:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29cc2c",
   "metadata": {},
   "source": [
    "The above conversions will ensure that later calculations will be correct since all the incorrect and missing values are now treated as missing values (NaN). This was done using 'errors=\"coerce\"' where cleaning up will not create new missing data but changing the already existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c661b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvknro:\n",
      "Unique values found: [np.int64(1), np.int64(2)]\n",
      "All values are valid.\n",
      "\n",
      "sp:\n",
      "Unique values found: [np.int64(1), np.int64(2)]\n",
      "All values are valid.\n",
      "\n",
      "ASALUE:\n",
      "Unique values found: [np.float64(1.0), np.float64(2.0), np.float64(3.0)]\n",
      "All values are valid.\n",
      "\n",
      "IKAL1:\n",
      "Unique values found: [np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84)]\n",
      "Invalid values found: [np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84)]\n",
      "\n",
      "A5:\n",
      "Unique values found: [np.float64(0.0), np.float64(1.0), np.float64(2.0), np.float64(60.0), np.float64(120.0), np.float64(420.0)]\n",
      "Invalid values found: [np.float64(0.0), np.float64(60.0), np.float64(120.0), np.float64(420.0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for ranges from the text file for variables pvknro, sp, ASALUE, IKAL1\n",
    "allowed_ranges = {\n",
    "    'pvknro' : {1,2},\n",
    "    'sp' : {1,2},\n",
    "    'ASALUE' : {1,2,3},\n",
    "    'IKAL1' : set(range(1,10)), # 1 to 9 \n",
    "    'A5' : {1,2} # yes/no  \n",
    "}\n",
    "\n",
    "for col, valid_values in allowed_ranges.items():\n",
    "    unique_values = set(df[col].dropna().unique())\n",
    "    invalid_values = unique_values - valid_values\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"Unique values found: {sorted(unique_values)}\")\n",
    "    if invalid_values:\n",
    "        print(f\"Invalid values found: {sorted(invalid_values)}\")\n",
    "    else:\n",
    "        print(\"All values are valid.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3bf6e",
   "metadata": {},
   "source": [
    "* Above verification is done because the missing values per column increased after converting the data types for the correct ones. \n",
    "    * pvknro, sp, ASALUE are all valid.\n",
    "    * IKAL1 which are age ranges which should only be from 1-9 have values more than 20. \n",
    "        * Therefore, it is assumed that the ages are entered insted of the relevant age group number.\n",
    "    * A5 should be having yes or no entries with either 1 or 2 to depict that the library was visited or not. But there are some float values entered. \n",
    "        * Therefore, it is assumed that those float values are the number of hours spent in the library which will then be entered as 1 (yes) to which it will be changed.\n",
    "\n",
    "#### Data correction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
